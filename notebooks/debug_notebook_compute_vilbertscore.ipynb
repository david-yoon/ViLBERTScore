{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39f4cc99",
   "metadata": {},
   "source": [
    "## dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bdb31667",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "59eb2977",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_custom import CaptioningDataset\n",
    "dataset = CaptioningDataset(path_image_feature = \"../data/sample/image_features.pkl\",\n",
    "                            path_gen_caption   = \"../data/sample/gen_captions.txt\",\n",
    "                            path_gt_caption   = \"../data/sample/gt_captions.txt\",\n",
    "                            savedir=\"../data/sample/\",\n",
    "                            use_idf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "60a36250",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, 3, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8d694396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/sample'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.datadir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663c20e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f73afb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c5a45f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0572cafe",
   "metadata": {},
   "source": [
    "## compute score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfccee9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/syoon/anaconda3/envs/vilbert-score/lib/python3.6/site-packages/tensorpack/callbacks/hooks.py:17: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/syoon/anaconda3/envs/vilbert-score/lib/python3.6/site-packages/tensorpack/tfutils/optimizer.py:18: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/syoon/anaconda3/envs/vilbert-score/lib/python3.6/site-packages/tensorpack/tfutils/sesscreate.py:20: The name tf.train.SessionCreator is deprecated. Please use tf.compat.v1.train.SessionCreator instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../vilbert\")\n",
    "from compute_vilbertscore_custom import VilbertScore\n",
    "vs = VilbertScore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6acfe784",
   "metadata": {},
   "outputs": [],
   "source": [
    "vs.loaddata(path_image_feature = \"../data/sample/image_features.pkl\",\n",
    "            path_gen_caption = \"../data/sample/gen_captions.txt\",\n",
    "            path_gt_caption = \"../data/sample/gt_captions.txt\"\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84447271",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 18.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target data path\n",
      "Images:  ../data/sample/image_features.pkl\n",
      "Generated Captions:  ../data/sample/gen_captions.txt\n",
      "Ground truth Captions:  ../data/sample/gt_captions.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rst = vs.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2ee5033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.9152127 , 0.9795474 , 0.95976865], dtype=float32),\n",
       " array([0.9168781 , 0.97922325, 0.9597212 ], dtype=float32),\n",
       " array([0.9160446 , 0.97938526, 0.95974493], dtype=float32)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2638567e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44d1b1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9dd1c669",
   "metadata": {},
   "source": [
    "## compute score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84f39ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import os\n",
    "import torch\n",
    "import yaml\n",
    "import logging\n",
    "logging.getLogger(\"pytorch_transformers\").setLevel(logging.CRITICAL)\n",
    "logging.getLogger(\"transformers\").setLevel(logging.CRITICAL)\n",
    "logging.getLogger(\"vilbert.utils\").setLevel(logging.CRITICAL)\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.CRITICAL)\n",
    "\n",
    "from easydict import EasyDict as edict\n",
    "from pytorch_transformers.tokenization_bert import BertTokenizer\n",
    "from vilbert.datasets import ConceptCapLoaderTrain, ConceptCapLoaderVal\n",
    "from vilbert.vilbert import VILBertForVLTasks, BertConfig, BertForMultiModalPreTraining\n",
    "from vilbert.task_utils import LoadDatasetEval\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import argparse\n",
    "import glob\n",
    "from types import SimpleNamespace\n",
    "import pdb\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import kendalltau\n",
    "from torch.nn.functional import softmax\n",
    "from utils import *\n",
    "# from dataset_direct import CaptioningDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714268b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c5c8908",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    'bert-base-uncased', do_lower_case=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8cfefb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = SimpleNamespace(from_pretrained= \"../data/vilbert/multi_task_model.bin\",\n",
    "                       bert_model=\"bert-base-uncased\",\n",
    "                       config_file=\"../config/bert_base_6layer_6conect.json\",\n",
    "                       max_seq_length=101,\n",
    "                       train_batch_size=1,\n",
    "                       do_lower_case=True,\n",
    "                       predict_feature=False,\n",
    "                       seed=42,\n",
    "                       num_workers=0,\n",
    "                       baseline=False,\n",
    "                       img_weight=1,\n",
    "                       distributed=False,\n",
    "                       objective=1,\n",
    "                       visual_target=0,\n",
    "                       dynamic_attention=False,\n",
    "                       task_specific_tokens=True,\n",
    "                       tasks='1',\n",
    "                       save_name='',\n",
    "                       in_memory=False,\n",
    "                       batch_size=1,\n",
    "                       local_rank=-1,\n",
    "                       split='mteval',\n",
    "                       clean_train_sets=True,\n",
    "                       dataset='flickr8k',\n",
    "                       task=7,\n",
    "                       layer=-1,\n",
    "                       expname='pretrain_cls_sep'\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ddc810f",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6792c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--compute_correlation'], dest='compute_correlation', nargs=None, const=None, default=False, type=<class 'bool'>, choices=None, help=None, metavar=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parser.add_argument(\"--dataset\", type=str, default=\"flickr8k\")\n",
    "# Use the task token \"7\" which is for \"Retrieval COCO\" in multi-task fine-tuned ViLBERT.\n",
    "parser.add_argument(\"--task\", type=int, default=7)\n",
    "parser.add_argument(\"--layer\", type=int, default=-1)\n",
    "parser.add_argument(\"--datadir\", type=str, default='data')\n",
    "parser.add_argument(\"--model_path\",type=str, default='../data/vilbert/multi_task_model.bin')\n",
    "parser.add_argument(\"--compute_correlation\",type=bool, default=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "352f5b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# args_ = parser.parse_args()\n",
    "# args.dataset = \"flickr8k\"\n",
    "args.datadir = \"../data/sample\"\n",
    "args.task = 7\n",
    "args.layer = -1\n",
    "args.from_pretrained = \"../data/vilbert/multi_task_model.bin\"\n",
    "args.compute_correlation = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e33e89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6f98fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../config/bert_base_6layer_6conect.json'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.config_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b42c11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "641abb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = BertConfig.from_json_file(args.config_file)\n",
    "with open('../vilbert_tasks.yml', 'r') as f:\n",
    "    task_cfg = edict(yaml.safe_load(f))\n",
    "    \n",
    "task_names = []\n",
    "for i, task_id in enumerate(args.tasks.split('-')):\n",
    "    task = 'TASK' + task_id\n",
    "    name = task_cfg[task]['name']\n",
    "    task_names.append(name)\n",
    "\n",
    "timeStamp = args.from_pretrained.split('/')[-1] + '-' + args.save_name\n",
    "config = BertConfig.from_json_file(args.config_file)\n",
    "default_gpu=True\n",
    "\n",
    "if args.predict_feature:\n",
    "    config.v_target_size = 2048\n",
    "    config.predict_feature = True\n",
    "else:\n",
    "    config.v_target_size = 1601\n",
    "    config.predict_feature = False\n",
    "\n",
    "if args.task_specific_tokens:\n",
    "    config.task_specific_tokens = True    \n",
    "\n",
    "if args.dynamic_attention:\n",
    "    config.dynamic_attention = True\n",
    "\n",
    "config.visualization = True\n",
    "num_labels = 3129\n",
    "\n",
    "if args.baseline:\n",
    "    model = BaseBertForVLTasks.from_pretrained(\n",
    "        args.from_pretrained, config=config, num_labels=num_labels, default_gpu=default_gpu\n",
    "        )\n",
    "else:\n",
    "    model = VILBertForVLTasks.from_pretrained(\n",
    "        args.from_pretrained, config=config, num_labels=num_labels, default_gpu=default_gpu\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "baf76c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../config/bert_base_6layer_6conect.json'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.config_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f299c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/vilbert/multi_task_model.bin'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.from_pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0ebd73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec8751f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdc9d19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f5c50e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dbdd1a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "cuda = torch.cuda.is_available()\n",
    "if cuda: model = model.cuda(0)\n",
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    args.bert_model, do_lower_case=args.do_lower_case\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "29f58fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/sample'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "savedir = os.path.join(args.datadir)\n",
    "savedir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22cfcf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "80b6bb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "from itertools import chain\n",
    "from collections import defaultdict, Counter\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "\n",
    "def process(a, tokenizer=None):\n",
    "    if not tokenizer is None:\n",
    "        a = [\"[CLS]\"]+tokenizer.tokenize(a)+[\"[SEP]\"]\n",
    "        a = tokenizer.convert_tokens_to_ids(a)\n",
    "    return set(a)\n",
    "\n",
    "def get_idf_dict(arr, tokenizer, nthreads=1):\n",
    "\n",
    "    \"\"\"\n",
    "    Returns mapping from word piece index to its inverse document frequency.\n",
    "    Args:\n",
    "        - :param: `arr` (list of str) : sentences to process.\n",
    "        - :param: `tokenizer` : a BERT tokenizer corresponds to `model`.\n",
    "        - :param: `nthreads` (int) : number of CPU threads to use\n",
    "    \"\"\"\n",
    "    idf_count = Counter()\n",
    "    num_docs = len(arr)\n",
    "\n",
    "    process_partial = partial(process, tokenizer=tokenizer)\n",
    "\n",
    "    with Pool(nthreads) as p:\n",
    "        idf_count.update(chain.from_iterable(p.map(process_partial, arr)))\n",
    "\n",
    "    idf_dict = defaultdict(lambda : log((num_docs+1)/(1)))\n",
    "    idf_dict.update({idx:log((num_docs+1)/(c+1)) for (idx, c) in idf_count.items()})\n",
    "    return idf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d06e5d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bert_score(model, text_a, input_mask_a, segment_ids_a, \n",
    "                       features, spatials, image_mask, co_attention_mask,\n",
    "                       input_idf_a, task, x, y, \n",
    "                       use_idf=False, layer=-1):\n",
    "    with torch.no_grad():\n",
    "        p5 = []\n",
    "        r5 = []\n",
    "        f5 = []            \n",
    "\n",
    "        st_c, sv_c, pt_c, pv_c, att_c = model.bert(\n",
    "            text_a[:,x,:], features, spatials, segment_ids_a[:,x,:],\n",
    "            input_mask_a[:,x,:], image_mask, co_attention_mask, task,\n",
    "        output_all_encoded_layers=True)\n",
    "        \n",
    "        for i in range(1):\n",
    "            st_g, sv_g, pt_g, pv_g, att_g = model.bert(\n",
    "                text_a[:,y+i,:], features, spatials, segment_ids_a[:,y+i,:],\n",
    "                input_mask_a[:,y+i,:], image_mask, co_attention_mask, task,\n",
    "            output_all_encoded_layers=True)\n",
    "            \n",
    "            if(use_idf):\n",
    "                p, r, f = bert_score(st_g[layer], st_c[layer], input_idf_a[:,y+i, :], input_idf_a[:,x, :])\n",
    "            else:\n",
    "                p, r, f = bert_score(st_g[layer], st_c[layer], input_mask_a[:,y+i, :], input_mask_a[:,x, :])\n",
    "                \n",
    "            p5.append(p)\n",
    "            r5.append(r)\n",
    "            f5.append(f)        \n",
    "\n",
    "    p5a = np.average(p5, axis=0)\n",
    "    r5a = np.average(r5, axis=0)\n",
    "    f5a = np.average(f5, axis=0) \n",
    "    \n",
    "    return p5a, r5a, f5a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad127105",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "847f36a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.9152127 , 0.9795474 , 0.95976865], dtype=float32),\n",
       " array([0.9168781 , 0.97922325, 0.9597212 ], dtype=float32),\n",
       " array([0.9160446 , 0.97938526, 0.95974493], dtype=float32)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = args.layer\n",
    "\n",
    "prs_a = []\n",
    "rcs_a = []\n",
    "f1s_a = []\n",
    "\n",
    "use_idf = False\n",
    "\n",
    "\n",
    "for text_a, input_mask_a, segment_ids_a, features, spatials, image_mask, co_attention_mask, input_idf_a, idxs_ in tqdm(iter(dataloader)):\n",
    "    text_a = text_a.cuda() \n",
    "    input_idf_a = input_idf_a.cuda()\n",
    "    input_mask_a = input_mask_a.cuda()\n",
    "    segment_ids_a = segment_ids_a.cuda()\n",
    "    features = features.cuda()\n",
    "    spatials = spatials.cuda()\n",
    "    image_mask = image_mask.cuda()\n",
    "    co_attention_mask = co_attention_mask.cuda()\n",
    "    task = [args.task]\n",
    "    task = torch.from_numpy(np.array(task)).cuda().unsqueeze(0).repeat(spatials.size(0), 1)\n",
    "#     break\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        p5a, r5a, f5a = compute_bert_score(model,\n",
    "                                           text_a,\n",
    "                                           input_mask_a,\n",
    "                                           segment_ids_a, \n",
    "                                           features,\n",
    "                                           spatials,\n",
    "                                           image_mask,\n",
    "                                           co_attention_mask,\n",
    "                                           input_idf_a,\n",
    "                                           task,\n",
    "                                           0,\n",
    "                                           1,\n",
    "                                           use_idf=use_idf,\n",
    "                                           layer=layer)\n",
    "        \n",
    "        if(len(prs_a) == 0):\n",
    "            print(\"her\")\n",
    "            prs_a = p5a\n",
    "            rcs_a = r5a\n",
    "            f1s_a = f5a            \n",
    "        else:\n",
    "            print(\"222\")\n",
    "            prs_a = np.concatenate((prs_a, p5a))\n",
    "            rcs_a = np.concatenate((rcs_a, r5a))\n",
    "            f1s_a = np.concatenate((f1s_a, f5a))\n",
    "\n",
    "final_results = [prs_a, rcs_a, f1s_a]\n",
    "final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b90bf22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e5f531",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20581e9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cdb21d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42438e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00b8379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b694e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66369dda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826bc3e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2221fa98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af4249d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb168fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126dfb27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8052c2bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d90cb8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030c67a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84957f82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:vilbert-score]",
   "language": "python",
   "name": "conda-env-vilbert-score-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
