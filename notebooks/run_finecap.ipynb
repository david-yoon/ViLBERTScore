{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b19a7f21",
   "metadata": {},
   "source": [
    "## 01. data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f7d47d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5063ce8c",
   "metadata": {},
   "source": [
    "### prepare test data - follow karpathy testset (order as well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9eafdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# karpathy split\n",
    "with open(\"../data/raw/coco/dataset_coco_karpathy.json\") as f:\n",
    "    karpathy = json.load(f)\n",
    "    \n",
    "karpathy_test = [ x for x in karpathy[\"images\"] if x[\"split\"] == \"test\"]      \n",
    "len(karpathy_test)\n",
    "\n",
    "with open(\"../data/processed/finecap/test_keys.txt\", \"w\") as f:\n",
    "    for item in karpathy_test:\n",
    "        f.write(str(item[\"cocoid\"]) + \"\\n\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8b9d9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f922a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read test_key\n",
    "with open(\"../data/processed/finecap/test_keys.txt\") as f:\n",
    "    test_key = f.readlines()\n",
    "    test_key = [x.strip() for x in test_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2477756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "# with open(\"../data/processed/finecap/clip_rn50_transformer_scl_pl_scst_cider_test.json\") as f:\n",
    "# with open(\"../data/processed/finecap/clip_rn50_transformer_scl_pl_scst_clipscore_test.json\") as f:\n",
    "with open(\"../data/processed/finecap/clip_rn50_transformer_scl_pl_scst_clipscore_grammar_normalized_test.json\") as f:\n",
    "    data = json.load(f)\n",
    "    data = data[\"imgToEval\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49923d55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7484528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# candidate caption\n",
    "with open(\"../data/processed/finecap/cand_clip_norm.txt\", \"w\") as f:\n",
    "    for key in test_key:\n",
    "        f.write(data[key][\"caption\"] + \"\\n\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf9422c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground truth caption\n",
    "\n",
    "# karpathy split\n",
    "with open(\"../data/raw/coco/dataset_coco_karpathy.json\") as f:\n",
    "    karpathy = json.load(f)\n",
    "karpathy_test = [ x for x in karpathy[\"images\"] if x[\"split\"] == \"test\"]      \n",
    "len(karpathy_test)\n",
    "\n",
    "with open(\"../data/processed/finecap/gt.txt\", \"w\") as f:\n",
    "    for key, item in zip(test_key, karpathy_test):\n",
    "        if key != str(item[\"cocoid\"]):\n",
    "            print(\"error\")\n",
    "            break            \n",
    "        else:            \n",
    "            for index, gt in enumerate(item[\"sentences\"]):\n",
    "                if index > 4:\n",
    "                    continue\n",
    "                f.write(gt[\"raw\"].strip() + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bfe3195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image path\n",
    "\n",
    "with open(\"../data/processed/finecap/imgs.txt\", \"w\") as f:\n",
    "    for key, item in zip(test_key, karpathy_test):\n",
    "        if key != str(item[\"cocoid\"]):\n",
    "            print(\"error\")\n",
    "            break\n",
    "        else:\n",
    "            f.write(\"../data/raw/coco/\" + item[\"filepath\"] + \"/\" +  item[\"filename\"] + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b907f0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700af8af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9075b76",
   "metadata": {},
   "source": [
    "## 02-A compute score - feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "472fe9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = \"../data/processed/finecap/imgs.txt\"         # input\n",
    "IMAGE_FEATURE = \"../data/processed/finecap/image_features.pkl\"  # output\n",
    "\n",
    "FEATURE_EXTRACTOR_BATCH_SIZE = 4\n",
    "DETECTRON_MODEL  = \"../data/detection/detectron_model.pth\"\n",
    "DETECTRON_CONFIG = \"../data/detection/detectron_config.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd803870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================== EVALUATION CONFIGURATION ======================\n",
      "Summary\n",
      "----------------------------------------------------------------------\n",
      " - model_file                         : ../data/detection/detectron_model.pth\n",
      " - config_file                        : ../data/detection/detectron_config.yaml\n",
      " - batch_size                         : 4\n",
      " - num_features                       : 100\n",
      " - output_folder                      : \n",
      " - image_dir                          : \n",
      " - feature_name                       : fc6\n",
      " - confidence_threshold               : 0\n",
      " - background                         : False\n",
      " - partition                          : 0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../vilbert\")\n",
    "from extract_features_custom import FeatureExtractor\n",
    "\n",
    "feature_extractor = FeatureExtractor(model_file    = DETECTRON_MODEL,\n",
    "                                     config_file   = DETECTRON_CONFIG,\n",
    "                                     batch_size    = FEATURE_EXTRACTOR_BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cd96b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(IMAGE_PATH) as f:\n",
    "    image_path = f.readlines()\n",
    "\n",
    "image_path = [x.strip() for x in image_path]\n",
    "# image_path = image_path[2500:]\n",
    "len(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f13dcf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [46:23,  4.57s/it]\n"
     ]
    }
   ],
   "source": [
    "img_features = feature_extractor.extract_features_direct(image_path)\n",
    "assert len(image_path) == len(img_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41b2814e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(IMAGE_FEATURE, \"wb\") as f:\n",
    "    pickle.dump(img_features, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f515bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "773503af",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/processed/finecap/image_features_01.pkl\", \"rb\") as f:\n",
    "    data_01 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "934f8dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/processed/finecap/image_features_02.pkl\", \"rb\") as f:\n",
    "    data_02 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81819fdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "data.extend(data_01)\n",
    "data.extend(data_02)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ae46c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/processed/finecap/image_features.pkl\", \"wb\") as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cd73b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cf6a97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e112380",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "161580af",
   "metadata": {},
   "source": [
    "## 02-B compute score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f982e542",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_FEATURE = \"../data/processed/finecap/image_features.pkl\"  # output from step 01\n",
    "GENERATED_CAPTION = \"../data/processed/finecap/cand_clip_norm.txt\"\n",
    "GT_CAPTION = \"../data/processed/finecap/gt.txt\"\n",
    "\n",
    "VS_BATCH_SIZE = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "923af829",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(\"../vilbert\")\n",
    "import pickle\n",
    "from compute_vilbertscore_custom import VilbertScore\n",
    "vs = VilbertScore(batch_size=VS_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6acb66ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 5000 25000\n",
      "num_itr:  5\n"
     ]
    }
   ],
   "source": [
    "with open(IMAGE_FEATURE, \"rb\") as f:\n",
    "    imgs = pickle.load(f)\n",
    "            \n",
    "with open(GENERATED_CAPTION, \"r\") as f:\n",
    "    cand_caps = f.readlines()\n",
    "    cand_caps = [x.strip() for x in cand_caps]\n",
    "\n",
    "with open(GT_CAPTION, \"r\") as f:\n",
    "    gt_caps = f.readlines()\n",
    "    gt_caps = [x.strip() for x in gt_caps]\n",
    "    \n",
    "print(len(imgs), len(cand_caps), len(gt_caps))\n",
    "num_itr = int(len(gt_caps) / len(cand_caps))\n",
    "print(\"num_itr: \", num_itr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f7625c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98501c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target data\n",
      "Generated Captions (2 samples):  ['a person wearing a red jacket riding a bike on a dirt path with the mountain', 'a young woman and a child eating a plate of cake at the table']\n",
      "Ground truth Captions (2 samples):  ['A man with a red helmet on a small moped on a dirt road.', 'A young girl inhales with the intent of blowing out a candle.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:52<00:00,  3.55s/it]\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target data\n",
      "Generated Captions (2 samples):  ['a person wearing a red jacket riding a bike on a dirt path with the mountain', 'a young woman and a child eating a plate of cake at the table']\n",
      "Ground truth Captions (2 samples):  ['Man riding a motor bike on a dirt road on the countryside.', 'A young girl is preparing to blow out her candle.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:52<00:00,  3.60s/it]\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target data\n",
      "Generated Captions (2 samples):  ['a person wearing a red jacket riding a bike on a dirt path with the mountain', 'a young woman and a child eating a plate of cake at the table']\n",
      "Ground truth Captions (2 samples):  ['A man riding on the back of a motorcycle.', 'A kid is to blow out the single candle in a bowl of birthday goodness.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:53<00:00,  3.61s/it]\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target data\n",
      "Generated Captions (2 samples):  ['a person wearing a red jacket riding a bike on a dirt path with the mountain', 'a young woman and a child eating a plate of cake at the table']\n",
      "Ground truth Captions (2 samples):  ['A dirt path with a young person on a motor bike rests to the foreground of a verdant area with a bridge and a background of cloud-wreathed mountains.', 'Girl blowing out the candle on an ice-cream']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:53<00:00,  3.63s/it]\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target data\n",
      "Generated Captions (2 samples):  ['a person wearing a red jacket riding a bike on a dirt path with the mountain', 'a young woman and a child eating a plate of cake at the table']\n",
      "Ground truth Captions (2 samples):  ['A man in a red shirt and a red hat is on a motorcycle on a hill side.', 'A little girl is getting ready to blow out a candle on a small dessert.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:53<00:00,  3.62s/it]\n"
     ]
    }
   ],
   "source": [
    "# multi gt case\n",
    "for i in range(num_itr):\n",
    "    \n",
    "    # subset of gt caption\n",
    "    sub_gt_cap = []\n",
    "    for index, cap in enumerate(gt_caps):\n",
    "        if index % num_itr == i:\n",
    "            sub_gt_cap.append(cap)    \n",
    "    \n",
    "    # load dataset to compute\n",
    "    vs.loaddata(list_image_feature = imgs,\n",
    "                list_gen_caption = cand_caps,\n",
    "                list_gt_caption = sub_gt_cap,\n",
    "                max_len=50\n",
    "               )\n",
    "    \n",
    "    precision, recall, f1 = vs.compute()\n",
    "    \n",
    "    if i==0:\n",
    "        df = pd.DataFrame(data=[precision, recall, f1]).T\n",
    "    else:\n",
    "        df_tmp = pd.DataFrame(data=[precision, recall, f1]).T\n",
    "        df = pd.concat([df, df_tmp])\n",
    "        \n",
    "df = df.rename(columns={0:\"precision\", 1:\"recall\", 2:\"f1\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a107b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5e67ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89df1dd8",
   "metadata": {},
   "source": [
    "### analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fce235d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53b763e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_precision = []\n",
    "for index in range( len(cand_caps) ):\n",
    "    scores_precision.append( np.sum(df[\"precision\"][index])/5 )\n",
    "    \n",
    "scores_recall = []\n",
    "for index in range( len(cand_caps) ):\n",
    "    scores_recall.append( np.sum(df[\"recall\"][index])/5 )\n",
    "    \n",
    "scores_f1 = []\n",
    "for index in range( len(cand_caps) ):\n",
    "    scores_f1.append( np.sum(df[\"f1\"][index])/5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd87fc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rst = pd.DataFrame([scores_precision, scores_recall, scores_f1]).T\n",
    "df_rst = df_rst.rename(columns={0:\"precision\", 1:\"recall\", 2:\"f1\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab931bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b42b306e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rst.to_csv(\"../data/processed/finecap/vilbertscore_clip_norm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fa374c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82b7291",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ac585de",
   "metadata": {},
   "source": [
    "### check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90cd014f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3587b38b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "precision    0.904526\n",
       "recall       0.886087\n",
       "f1           0.894967\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cider = pd.read_csv(\"../data/processed/finecap/vilbertscore_cider.csv\")\n",
    "df_cider.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e17097c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "precision    0.812533\n",
       "recall       0.868545\n",
       "f1           0.839295\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clip = pd.read_csv(\"../data/processed/finecap/vilbertscore_clip.csv\")\n",
    "df_clip.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e6f43a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "precision    0.877505\n",
       "recall       0.884602\n",
       "f1           0.880798\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clip_norm = pd.read_csv(\"../data/processed/finecap/vilbertscore_clip_norm.csv\")\n",
    "df_clip_norm.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa16063",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385367ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13854dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c8665a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e10d3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:vilbert-score]",
   "language": "python",
   "name": "conda-env-vilbert-score-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
